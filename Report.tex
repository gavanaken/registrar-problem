\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}
\usepackage[]{algorithm2e}
\geometry{letterpaper}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{parskip}

\graphicspath{ {images/} }

\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
%SetFonts

\title{CS340 - Registrar Project}
\author{Greg Van Aken, Conor Stuart Roe, Russell Gerhard}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\section{Description}
Our algorithm assigns conflict scores to each pair of classes based on teacher assignments and student preferences. If two classes are in a student's preference list, then their conflict score is incremented by 1. If two classes are taught by the same professor, then their conflict score is set to infinite. We store these scores in a 2D array, where each column and each row represent a class. As a direct result, we only use the upper triangle of the 2D array. To ensure that we only need to use the upper triangle of the matrix, we will adopt the convention of indexing such that $i < j$, where $i$ is the row index and $j$ is the column index. A union-find object is used to represent class groups, with each class group eventually corresponding to all the classes scheduled in a given time slot.

Initially, all classes are in their own sets. A priority queue of class pairs, organized by their conflict score, allows us to union the class groups with minimum conflict score. This is reflected in the array by selecting one column and corresponding row to correspond to the conflict scores of the newly merged class group (as opposed to actually re-sizing the array by removing columns and rows). It is worth noting that there are a few subtleties with this treatment. First, it is common that one or both sets specified to be merged have already been merged with some other set, in which case the pair of class groups to be merged is disregarded (i.e. the union and thus the merge do not occur). Second, if the number of classes in a class group created by a merge is larger than the number of classrooms, then the merge is disregarded (as we cannot have, say, 20 classes at time 1 when there are less than 20 rooms).

After a merge, conflict scores are re-evaluated, as every class group has a new conflict score with the merged group that is equal to the sum of the conflict scores with each component class group. For example, if groups $s_i$ and $s_j$ are merged to form $s_k$, then every other group, $s_o$, now has a conflict score with $s_k$ equal to the sum of its conflict with $s_i$ and its conflict with $s_j$. Each merge reduces the number of class groups by 1; once the number of class groups is equal to the number of time slots, each class group can be assigned to a time slot.

Finally, we create the schedule in a dictionary whose keys are course numbers and values are dictionaries containing room, time, teacher, and the student list for each course. We fill out this dictionary from the constraints such that:

\begin{enumerate}
    \item Each group of classes becomes associated with a time slot, and every class in that group takes place at that time.
    \item The larger classes in a given class group get the larger rooms (this requires some sorting).
    \item The number of students in a class does not exceed the capacity of the assigned room. If this occurs, we remove students until they fit the room capacity.
\end{enumerate}

In addition to the basic functioning of our algorithm, we handled several extensions, which we briefly describe here (for more depth, see the extensions section).

 First, we allowed students to assign preference weights to their courses. In this way, students may indicate which courses they prefer the most. We implemented this by parsing an additional weights input file and incrementing the conflict score of a class pair by the sum of the component classes' weights when they appear in a student's preference list.

Second, we assumed minimum conflict between 100- and 300-level courses in the same department. We accomplished this by parsing an additional department-and-levels input file and merging 100- and 300- level courses in the same department first.

Third, we used student preference lists to drop students from courses. With this option, any time a student would be required to drop a course due to overenrollment or requesting two simultaneous classes, the lower-preference class was the one which would be dropped.

Fourth, we implemented a system to keep track of overenrolled students and used this system when cutting students from overenrolled classes. Rather than a totally random lottery, overfull classes would preferentially drop overenrolled students. As this happened, the students' overenrollment status would be updated, so that they would not continue to be singled out after dropping to four classes.

Fifth, we allowed for Bryn Mawr data and assumed no conflict between Haverford and Bryn Mawr courses which satisfy the same requirement (e.g. Analysis of Algorithms).  While we tested this feature on data we generated, the implementation would allow for two dictionaries to be passed in as input, one whose keys are course numbers and values are the campus at which the course is being taught, and one whose keys are course numbers and value are other courses to which the key-course is equivalent.

Sixth and finally, we allowed for arbitrarily large student preference lists, as well as arbitrarily large course lists for professors. This did not require additional implementation, as our base algorithm iterated through all courses in each student preference list and all courses in each professor's course list.

\section{Pseudocode}
\begin{algorithm}
\SetKwFunction{Main}{Main}
\SetKwProg{Fn}{Function}{}{}
\Fn{\Main{Preferences, numClasses, Teachers}}{
let $n$ = len(numClasses);
initialize $M$ = n x n 2-D array of all 0's;

$M$ = setTeach($M$, $Teachers$);

$M$ = setCost($M$, $Preferences$);

createSets(M);

}
\end{algorithm}

\begin{algorithm}
\SetKwFunction{setTeach}{setTeach}
\SetKwProg{Fn}{Function}{}{}
\Fn{\setTeach{M, Teachers}}{
sort $Teachers$ by teacher id // Teachers is a list of class-teacher pairs \\
initialize $prev$ = Teachers[0] \\
\While{$i=1 < len(Teachers)$} {
let $teach$ = Teachers[i] \\
\If{teach[1] == prev[1]} {
set $M$[teach[0]][prev[0]] to $infinity$ // teacher teaches both classes \\
}
set $prev$ = Teachers[i] \\
i++ \\
}
\Return{$M$}
}
\end{algorithm}

\begin{algorithm}[H]
\SetKwFunction{setCost}{setCost}
\SetKwProg{Fn}{Function}{}{}
\Fn{\setCost{M, Preferences}}{
\For{student in Preferences} {
// Assume Preferences = [[p1,p2,p3,p4],[p1,p2,p3,p4],...]

\For{i in range(0:4)} {
{
\For{j in range(i+1:4)} {
let $c1$ = student[i]; let $c2$ = student[j];

$M$[$c1$][$c2$] += 1 // assuming unsorted/unweighted
}
}
}
}
}
\end{algorithm}

\begin{algorithm}[H]
\SetKwFunction{createSets}{createSets}
\SetKwProg{Fn}{Function}{}{}
\Fn{\createSets{M}}{
    \# M is an $n$ by $n$ matrix \\
    Initialize a union-find object, $S$ \\
    \For{each class}{
         Initialize a disjoint set of size one containing that class, stored in $S$ \\
    }
    Initialize a priority queue $P$ with all values from M in it \\
    \While{number of sets in $S$ $\geq$ the number of time slots}{
        Pop $(S_i, S_j)$ \\
        \If {either $S_i$ or $S_j$ has already been merged} {pass}
        \ElseIf{$|S_i|+|S_j| \leq$ the number of classrooms}{
            merge $S_k = S_i \cup S_j$ \\
            Add row and column $j$ to row and column $i$ \\
            Designate row and column $i$ as the location of $S_k$'s conflict scores \\
            Push all of $S_k$'s conflict scores to $P$ \\
        }
    }
    \For{each disjoint set $s$ in $S$}{
        assign $s$ to an unassigned time slot \\
        \For {each class $c$ in $s$}{
            assign $c$ to an unassigned classroom
        }
    }
\# write output to a file
}
\end{algorithm}

\begin{algorithm}
\SetKwFunction{createSchedule}{createSchedule}
\SetKwProg{Fn}{Function}{}{}
\Fn{\createSchedule{}}{
    initialize an empty dictionary, S \\
    roomSorted = sorted rooms by room size \\
    \For{each course}{
        S[course] = a dictionary containing 4 key-value pairs for room, teacher, time, and student list \\
    }
    \For{each course}{
        S[course][teacher] = teacher of that course, as given by constraints \\
    }
    \For{each preference list P}{
        \For{each course in P}{
            S[course][student list] = append the student whose preference list we are examining \\
        }
    }
    \# This next variable is used to compute groupSorted below \\
    classSorted = sorted courses by how many students want to take them \\
    \For{group,i in enumerate(classGroups)}{
        groupSorted = sort courses in group by how many students want to take them \\
        \For{each course,j in enumerate(groupSorted}{
            S[course][time] = i \\
            S[course][room] = $j^{th}$ element of roomSorted \\
        }
    }
    create a dictionary, R, from room constraint, where rooms are keys and room sizes are values \\
    \For{each course}{
        check that the size of it's students list is not greater than the room size of the room to which it's assigned \\
        If there are too many students, remove as many as needed until they fit into the given room size \\
    return S \\
    }
    }
\end{algorithm}

\# We have omitted the function that writes the output file, as it is merely an implementation detail once the schedule object has been created by \textit{createSchedule}. \\

\newpage
\section{Time Analysis}

Call the number of teachers $t$, the number of students $s$, the number of rooms $r$, and the number of classes $n$. \\

 setTeach contains a sort of teachers, which takes $O(t$log$t)$ time. Then it iterates over teachers performing constant time operations, so taking $O(t)$ time. Overall, setTeach is $O(t$log$t)$. \\

 setCost contains a triply nested loop, but the number of iterations of the innermost loop is equal to the total number of requests made by students. On our early data sets, each student would request exactly 4 courses; this requirement was removed, and the Haverford data contains up to nine requests per student, but it is reasonable to assume that the average courses requested per student remains relatively tightly bound to the size of a full course load and certainly does not grow as other inputs do. With this assumption, the total time is $O(s)$. \\

 createSets is a more complex function. The way it is written, initialization of the Union-Find, which contains one set per class, is $O(n)$. Initializing the priority queue is constant, but pushing all $O(n^2)$ values of $M$ to it is $O(n^2$log$(n^2)) = O(n^2$log$n)$. All sets must be merged by the time the priority queue is empty, so the maximum number of iterations of the \textbf{while} is no more than the maximum number of entries ever created in the priority queue $P$. Since every group merge reduces the number of class groups by 1, at most $n-1$ merges may take place, so at most $2n-1$ groups can ever be created before all classes are in one group. Each conflict score is between two groups, so the total number of possible conflicts to store in $P$ is $O((2n-1)^2) = O(n^2)$. The time of popping from $P$ is $O($log$(n^2)) = O($log$n)$. Checking whether a group has already been merged, checking the group sizes of $S_i$ and $S_j$, and merging sets are all constant time with our data structures. Adding rows and pushing them to $P$ can occur in total as many times as there are possible conflict scores, again $O(n^2)$, so it does not actually increase the time complexity of the \textbf{while}. Overall the most complex operations that occurs for every loop are the pop and push to $P$, which are $O($log$n)$, so the total complexity of the \textbf{while} is $O(n^2$log$n)$. Lastly, the double \textbf{for} iterates over all classes, performing a constant time operation of assignment, so its complexity is $O(n)$. The dominating complexity of createSets is $O(n^2$log$n)$. \\
 
 Finally, we have createSchedule. The initialization of S is $O(1)$. Sorting the list of rooms is $O(log(r))$. The dictionary is implemented as a hash table, which will be unfortunate for this section of analysis, as – technically – worst case, insertion and search are $O(k)$, where $k$ is input size. Hence, it is worth noting that the dictionary was selected for its amazing $O(1)$ \textit{average-case} complexity. Additionally, we note that the 'inner' dictionary contains only four key-value pairs, so insertion and search are constant. Continuing the analysis, the first for loop runs $n$ times and makes an insertion in each iteration, however, for this for loop, assignments are unlikely to generate hashing conflicts (as we are filling out the dictionary), so we do not consider them to be $O(n)$, but rather, $O(1)$. Thus, the first for loop is $O(n)$. The second for loop runs $n$ times and makes an insertion at each iteration, so it is $O(n^2)$. The third and fourth for loops are nested, but the fourth for loop only runs the size of the student preference lists, which is constant. The third for loop runs $s$ times, and an insertion is made during each iteration. Thus, the third and fourth for loops run in $O(sn)$ time. The fifth and sixth for loops are nested, but the fifth iterates over a constant number of class times, so we only consider the sixth for loop for time complexity analysis. It runs $n$ times, making two insertions, so it runs in $O(n^2)$ time. The seventh for loop iterates over all courses, running $n$ times, doing a lookup at each iteration and removing at most $n-1$ students if there are too many students for a given room size. So the seventh for loop runs in $O(n*(n+n-1)) \in O(n^2)$ time. Since we don't know whether $s$ is bigger than $n$, we cannot be sure which term dominates, and thus, createSets runs in $O(sn+n^2)$ time. \\
 
 Each function is performed once during the algorithm's run, so the time complexity is their sum $O(t+s+n^2$log$n + sn+n^2)$. Assuming that the number of classes taught by each teacher closely hews to an average, the number of teachers is linear relative to the number of classes - under this assumption, the algorithm runs in $O(sn + n^2$log$n)$. \\

\section{Discussion}

We had a relatively good intuition when approaching this problem that we had to somehow compute a cost associated with having classes at the same time. One option we considered was to weight the cost according to how many students preferred a given class. In other words, for every student that lists some class as their first choice, add a cost of 4 to that class. For every student who lists it as their second choice, add a cost of 3, etc. We realized that although this would determine a set of highly preferred classes that may have a number of students wanting to take them (and thus should not overlap), it loses the logic about what each student wants. A counter example to our initial approach is that there are two popular courses but they occur in different majors. There may be a lot of students who prefer those classes, but few students will desire to take both courses. Thus, it would be reasonable for those classes to overlap. This led us to our current algorithm which makes decisions based on the cost to each student of having two classes overlap. The aspects of this problem which made it difficult to determine an algorithm are:
\begin{enumerate}
\item{How do we quantify the cost of two classes overlapping?}
\begin{itemize}
\item{We decided to set it up such that merging courses is a direct function of the number of students who desire to take both}
\end{itemize}
\item{After a minimum cost is found and then a merge takes place, the cost of merging any third class with the new set will have to include the total merge cost of the third class with every class already in the set} 
\begin{itemize}
\item{This fact led us to the idea of merging matrix rows/columns to reflect the additive costs when sets are merged}
\end{itemize}
\item{A given teacher cannot teach more than one class at a given time}
\begin{itemize}
\item{This issue led us to perform the initialization step of setting matrix cells coorresponding to classes taught by the same teacher to Infinity}
\end{itemize}
\item{A given time slot cannot have more classes scheduled than the given number of rooms}
\begin{itemize}
\item{Because of this, we decided to check to see if this condition is broken and if so, skip that merge}
\end{itemize}
\end{enumerate}

This algorithm is {\bf greedy} because each time work is done, it generally follows a simple rule: merge sets with the lowest merge cost (if a merge is valid). Interestingly enough, creating one class group to be put in a time slot is similar to constructing a minimum spanning tree using Kruskal's algorithm. Classes can be thought of as nodes in a graph and merge cost can be thought of as the weight of the edge between nodes. Similar to a minimum spanning tree, minimum edge weights are selected as the sets are constructed (merged).

One very important pitfall of our algorithm to note is that it can schedule professors to teach different courses at the same time. Above, the third note on the difficulty of the algorithm states that we initialize the conflict score of class pairs with professor conflicts to infinite. When designing the algorithm, we believed that, since infinite should never be the cheapest merge, we \textit{should} never have two courses taught by the same professor in the same time slot. However, the algorithm is greedy, and does not backtrack, so it can run into a problem where the only available merge has an associated cost of infinite, and thus, infinite \textit{is} the cheapest merge. This arises because of the fourth note on the difficulty of designing an algorithm: if a merge produces a class group with more classes than there are rooms, then the merge is ignored. Hence, if every non-infinite merge creates a class group that is too large, then the algorithm is forced to make a merge with infinite cost, as it must reduce the number of class groups to the number of time slots available.

This is a large issue, as the algorithm fails to produce a valid schedule when this error occurs. For more information regarding a potential solution to this error, refer to the \textit{Design Error} section.

A final note on our algorithm comes after having seen the presentations of other groups: Lizzy Chan, Tessa Pham, and Xinyi Wang presented an algorithm which utilized a dictionary keyed by class pairs to store their conflict costs, and we all agree that, were we to start the project over again, using a dictionary to store conflict costs would be cleaner and more intuitive than using the upper triangle of a 2D array, which forces cells to continuously be repurposed as sets of classes are merged.

\subsection{Implementation}
We chose to implement this algorithm in Python. Much of the implementation followed directly from our design and pseudocode. One important need of the algorithm was efficient, powerful implementations of the two key data structures - a Union-Find and a priority queue.

We were able to adapt the {\it unionfind} package hosted on {\it https://pypi.org} (licensed to The Python Software Foundation). Our modifications included the following: In the original version, the objects being binned into sets must be a contiguous range of integers; we abstracted the set items away from the internal indices, so that arbitrary objects could be collected into sets. We also made the union-find continuously track its number of sets. Overall, the union and find operations are both $O(1)$ in averages.

We also implemented our own min heap to serve as the priority queue, with a few additional non-standard features. Each node keeps track of how many nodes are to its left and right, and self-balances by sending added nodes to the sparser side, hopefully maintaining logarithmic access time. It allows for setting a custom key for sorting stored objects; since we pushed 3-tuples to the queue, of which the last element was the conflict score, we used the custom key feature to sort by third element. Lastly, our priority queue kept track of its size.

We chose to implement the final schedule as a nested dictionary: each course number is a key that corresponds to a dictionary value; this 'inner' dictionary contains keys whose corresponding values are the teacher, time, room, and student list for the course. We chose this implementation because the schedule information will be accessed often (by students, teachers, and the registrar alike) once it is computed, and the hash table behind Python's built-in dictionary allows for average-case O(1) lookup.

\section{Experimental Analysis}
\subsection{Performance}
The algorithm was tested using a number of different random test cases where the number of classes, students, times, and rooms were varied. These results are summarized in Table 1. In many cases the algorithm quickly produced a schedule (in less than 1 second), except for a few with large inputs. Furthermore, many of the resulting schedules were relatively optimal, with a mean of 94\% of students (and a $10^{th}$ percentile of 92\% of students) ultimately enrolled in their preferred classes.
\begin{table}[h]
\centering
\begin{tabular}{lllllllll}
no. & Classes & Students & Times & Rooms & Time (sec) & Best   & Experimental & \% Optimality \\
1   & 20      & 100      & 5     & 10    & 0.0094     & 400    & 324          & 0.81         \\
2   & 20      & 100      & 10    & 5     & 0.0060     & 400    & 381          & 0.9525       \\
3   & 20      & 200      & 5     & 10    & 0.0127     & 800    & 637          & 0.79625      \\
4   & 20      & 200      & 10    & 5     & 0.0111     & 800    & 758          & 0.9475       \\
5   & 40      & 200      & 10    & 20    & 0.0349     & 800    & 749          & 0.93625      \\
6   & 40      & 200      & 20    & 10    & 0.0220     & 800    & 772          & 0.965        \\
7   & 40      & 400      & 10    & 20    & 0.0390     & 1600   & 1469         & 0.918125     \\
8   & 40      & 400      & 20    & 10    & 0.0276     & 1600   & 1560         & 0.975        \\
9   & 80      & 400      & 30    & 30    & 0.0904     & 1600   & 1522         & 0.95125      \\
10  & 80      & 600      & 30    & 30    & 0.1016     & 2400   & 2312         & 0.963333333  \\
11  & 100     & 600      & 30    & 30    & 0.1567     & 2400   & 2286         & 0.9525       \\
12  & 100     & 800      & 30    & 30    & 0.1595     & 3200   & 3073         & 0.9603125    \\
13  & 100     & 1000     & 30    & 30    & 0.1638     & 4000   & 3863         & 0.96575      \\
14  & 100     & 2000     & 30    & 30    & 0.1869     & 8000   & 7843         & 0.980375     \\
15  & 200     & 1000     & 30    & 30    & 0.6815     & 4000   & 3752         & 0.938        \\
16  & 200     & 2000     & 30    & 30    & 0.7009     & 8000   & 7679         & 0.959875     \\
17  & 200     & 3000     & 30    & 30    & 0.7316     & 12000  & 11701        & 0.975083333  \\
18  & 500     & 1000     & 60    & 50    & 5.1768     & 4000   & 3714         & 0.9285       \\
19  & 500     & 2000     & 60    & 50    & 5.1586     & 8000   & 7536         & 0.942        \\
20  & 500     & 5000     & 60    & 50    & 5.1397     & 20000  & 19257        & 0.96285      \\
21  & 500     & 10000    & 60    & 50    & 5.2976     & 40000  & 39061        & 0.976525     \\
22  & 2000    & 40000    & 60    & 300   & 117.0473   & 160000 & 156211       & 0.97631875  
\end{tabular}
\caption{Results of running the algorithm with various parameters}
\label{my-label}
\end{table}
Because we suspect that the time of the algorithm is largely dominated by the number of classes ($n$), we decided to plot class size against running time for the various experiments above. According to our timing analysis the algorithm should run $O(n^2logn)$. For this reason, we plotted the number of classes against the square root of the time to try and observe a linear relationship. Because of the nature of the way we increased class number, we decided to report it on a log scale. The results of this can be seen in Figure 1. We observe a relatively linear relationship suggesting that the running time is squared in the number of classes.
\begin{figure}[h]
\includegraphics[width=\linewidth]{"Timing Data".png}
\centering
\caption{The square of running time as a function of the number of classes (log scale) for the experimental results.}
\end{figure}

\subsection{Design Error}
After testing the algorithm, we realized that there is a flaw in the design that is capable of producing invalid schedules. If a circumstance is arranged such that the number of rooms is somewhat constrained (relative to the number of classes), the algorithm may find itself backed into a corner due to the \textbf {greedy} approach. At any time, a set combination may be popped from the priority queue which currently has the minimum conflict. However, merging these sets would produce a set which is too large (greater than the number of available rooms) and this combination is ignored. If this occurs continuously, eventually a merge will take place with an infinite conflict score, corresponding to two courses taught by the same teacher. Since there is no way to backtrack and "unmerge" sets, there is no choice but to merge them, which produces an invalid schedule. Again, this is only observed when the number of available rooms is small. For the haverford data, as well as a number of "realistic" random tests, we did not encounter this problem. However, it is important to note that it is present and a direct drawback from the \textbf {greedy} approach.

If we want to ensure that a valid schedule is always formed, we could relax the restriction on the maximum size of a set. Then, all merges will be minimum. For any set which is ultimately larger than the number of available rooms we can randomly remove classes and merge them into one of the other smaller sets. If all other sets produce infinite conflicts, then pick a new class to attempt to move. If there is such a time when all classes in the overfilled time slot conflict infinitely with all other sets, then pick the course with the minimum student interest and remove it altogether (do not schedule it at all).

This may create problems with our optimality for cases where this issue would never arise. At some step in the algorithm, merging the "next best option" may be better than the result of the above process. To handle this, our algorithm could proceed normally and if and only if infinitely conflicting courses are merged, the algorithm starts over following the above design. Ultimately these desicions balance the choice between optimality and complexity and may be case-dependent. 

\section{Additional Constraints}

We implemented a number of new constraints, most as options to be triggered by CLI flags. The flags include "--weighted", "--normed", "--levels", and "--schools" - their usage will be noted.

\begin{enumerate}
\item{\textbf{Weighted Preference Costs}}

When students select which classes they are going to take, it is rarely the case that taking each course bears equal importance to their academic pursuits. An example of this could be courses a student needs for their major or minor. Another example may be courses a student needs to take in order to fulfill remaining distribution requirements. The current student preferences file convention does not weight a given student's desired courses, it assumes that any combination of courses occurring at the same time is equally problematic. However, if we enforce that students sort their courses in order of preference and weight each one up to a total constant weight value (we chose 10), then we can compute the cost of merging according to the following formula:\\

$cost(c_i,c_j) = weight[c_i] + weight[c_j]$

This way, courses with higher weights have a higher overlap cost than courses with lower weights. Our algorithm takes this convention into account when it sets costs. When our program is run with the flag "--weighted", it looks for a file constructed according to the convention below. Then, conflicts are computed according to the above formula. Total maximum student preference value is also re-computed along this process because it will be a function of not just whether a student is enrolled in a course, but also of the $weight$ of the courses they are enrolled in. Since we have constrained the weight to 10, this is just $10\times \#students$. Once a schedule is generated, the student preference value is checked using our added script "pref\_value\_sorted.py". Note that "is\_valid.pl" must still be used to report schedule accuracy, but the value it gives for student preference does not take priorities into account.\\

The added constraints are passed through a file of the following format:\\

student\qquad weights \\
1\qquad 5 3 1 1 \\
2\qquad 4 2 2 1 1 \\
3\qquad 3 3 2 2  \\

Where weights are space-separated weights (totalling 10) for each student ordered the same as the student's list of classes in the preferences file

Registering for two courses does not mean that one wants to enroll in them equally. Thus, it is important to consider which courses would be most problematic to overlap. For this reason, adopting this added constraint improves the overall optimality of the algorithm in computing high preference schedules. The take away from this design change is that when scheduling courses, the registrar should take into account the (implicit) preferences of students. For example, if there are a lot of students who are computer science majors / math minors, a number of students will highly prefer taking those courses concurrently and they shouldn't be scheduled together. Similarly, if a number of junior computer science majors have outstanding distribution requirements in the humanities, the registrar should ensure that not too many CS courses are scheduled on top of humanities courses.\\

\item{\textbf{Conflict Assumptions}}

In reality, the registrar does not have student preferences to work with. Therefore, it is impossible to use our algorithm to make scheduling decisions. We can, however, use our algorithm to check the accuracy of an implementable standard for course scheduling. In this case, we wanted to test the assumption that 100-level and 300-level courses in the same department/subject are rarely taken by the one student. To do this, we wrote a script "dept\_level\_data.py" which parses Haverford Enrollment Data to output the subject and level for each course and writes it to a file "DeptLevels.txt". This file can be supplied to our algorithm following the flag "--levels". With this added information, the algorithm sets 100-level and 300-level courses from the same subject to $0$ conflict in the conflict matrix $M$, regardless of what they were set to before (unless it was "Infinity" - one teacher still cannot teach two courses at the same time). This effectively enforces the assumption that such a course pair will not have any individual student interest. The algorithm is then able to run normally. The results of this change are summarized in Table 2.\\

\begin{table}[h]
\centering
\begin{tabular}{lllll}
Experiment        & Time          & Best & Experimental & \% Optimality \\
Regular Algorithm & 2.94600010    & 4427 & 3718         & 0.83985       \\
With Assumption   & 3.00800013542 & 4427 & 3697         & 0.83510      
\end{tabular}
\caption{Results of running the algorithm on Haverford Data with and without the added constraint}
\label{my-label}
\end{table}

It makes sense that the added constraint adds a bit of time because it iterates over M a second time and modifies the values. This extra complexity could be avoided by checking the courses when costs are initially set, however the focus of this experiment was to evaluate optimality. It is clear that the total preference value only dropped marginally by enforcing this assumption. After seeing this, we wanted to probe the enrollment data further to see which courses contribute to this marginal drop in optimality.

After analyzing the Haverford Data further, we found that in 2014, there were 44 cases of a student concurrently enrolling in a 100-level and 300-level course in the same subject. We also found that these 44 cases were confined to only 13 departments. In many cases, there were a few (1-3) instances for a given department, but some (Political Science, Music, and Psychology) had a higher number of occurrences (5-9), as shown in Table 3.\\

\begin{table}[h]
\centering
\begin{tabular}{llll}
Subject & Occurrences & Subject & Occurrences \\
CITY    & 1           & RELG    & 3           \\
SOCL    & 1           & ARTS    & 3           \\
SPAN    & 1           & ANTH    & 3           \\
ICPR    & 1           & MUSC    & 5           \\
HIST    & 1           & POLS    & 9           \\
PHIL    & 1           & PSYC    & 11          \\
LING    & 2           &         &             \\        
\end{tabular}
\caption{Occurrences per subject of concurrent enrollment in a 100- and 300-level course in one subject}
\label{my-label}
\end{table}

The results of this experiment show that the registrar can produce relatively optimal schedules by scheduling 100- and 300-level courses from the same subject at the same time (as long as they are not taught by the same teacher). In fact, if the above trends are observed over various years, the registrar may avoid grouping together 100- and 300-level courses from subjects like Political Science and Psychology, but group together 100- and 300-level courses from other subjects and improve the optimality of course scheduling.\\

\item{\textbf{Class Dropping by Preference}}

When we have the advantage of access to weighted student preferences as in the first additional constraint, it only makes sense that, when students find themselves in a situation of needing to drop a class, their lowest preference class gets dropped. The preference lists were utilized to that end in two different scenarios in which students must be dropped from a class. Both uses of the preference list require the "--weighted" flag in order to be triggered. 

In the first case, when two or more of a student's requested classes become scheduled simulatenously, they must drop all but one of the simultaneous classes. With this feature, the class retained is always their highest-priority class from among the conflicting classes.

In the second case, when a student is overenrolled, the classes they drop to acheive a normal course load should be those they rank as least important. This feature is triggered not by sole use of the "--weighted" flag, but by combination with the "--normed" flag, which stipulates that student course loads should be normalized down to 4 courses.

\item{\textbf{Course Load Normalization}}

Triggered by the "--normed" flag are two features related to normalizing course load down to 4 for each student. Such a constraint closely matches the demands of the real world - especially in popular majors like computer science, it is common for students to attempt registration for many more courses than they intend to take. This feature allows students to do just that, requesting every course they have interest in with the guarantee that they will not need to overload. In combination with preference weighting it becomes extra powerful, as students can request additional courses without fear that it will negatively affect their odds in the most important classes. It also adds an important element of fairness when running class lotteries - overenrolled classes will prefer to drop students with backup options.

As background, it must be remembered that the algorithm assigns students to classes in three steps. It first fulfills all student requests, only blocking the addition of courses at a time when a student already has a course. Secondly, it checks classes for overenrollement and drops students from overenrolled courses. Thirdly, and only with the "--normed" flag, it drops classes for students with more than 4 courses.

With the "--normed" flag, a record is maintained through all three steps of students with more than 4 courses. The record is filled in the first step, when students are added to courses without regard to course or student overenrollment. At the second step, overenrolled courses preferentially drop students with more than 4 courses, opting to drop random students only once all such students have been dropped. At the same time, if a student becomes dropped, the overenrollment record is updated, so that if their number of courses dips to 4 they will no longer be preferentially dropped from other overenrolled courses. At the third step, all students remaining in the overenrollment record drop courses until they have 4.

\item{\textbf{Bryn Mawr and Haverford Classes}}

It is the often the case at Haverford and Bryn Mawr that students sign up for two classes which they will never take concurrently. One such example is when two versions of the same course are offered at Haverford and Bryn Mawr. In this case, we implemented immediate grouping for any such classes which are deemed 'equal' by the registrar. This approach has clear advantages: the registrar can schedule some classes at the same time without worrying that any students will need to take them concurrently. However, this solution does not come without cost. Consider, for example, the case in which a student's higher-preferred course conflicts with the single time slot assigned to both versions of a course the student wants to take. Scheduling both versions at the same time prevents this student from taking \textit{either} version. If the two versions were scheduled at different times, then the student's conflict with one time slot could potentially be resolved by scheduling them in the version whose time slot does not conflict. In light of this hidden cost, which is not necessarily reflected in our conflict cost representation of the problem, exploration of this extension has led us to recommend that the registrar \textit{not} schedule equivalent versions of a class in the same time slot.

\end{enumerate}


\end{document}