\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}
\usepackage[]{algorithm2e}
\geometry{letterpaper}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{parskip}

\graphicspath{ {images/} }

\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
%SetFonts

\title{CS340 - Registrar Project}
\author{Greg Van Aken, Conor Stuart Roe, Russell Gerhard}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\section{Description}
This algorithm works by assigning conflict scores to each pair of classes based on teacher assignments and student preferences and assigning each class to be the sole member of a set, then continuously merging sets of classes (designating them to occupy the same time slot) in a greedy manner, on the basis of lowest total set conflict scores. \\

Call the number of classes as $n$. Initialize a "conflict matrix" $M$, an $n \times n$ 2-D matrix for storing conflict scores, setting all values to 0. Additionally, create a union-find object $S$ and assign each class to its own set within $S$. For each teacher, each pair of classes they teach ($c$, $c^\prime$) definitely cannot occupy the same time slot, so the conflict score $M[c][c^\prime]$ is set to {\it Infinity} (or some sufficiently large number). Then each student's preference list is iterated through, and for each class pair $(c, c^\prime)$ in a given student's preference list, where $c$ is at index $i$ and $c^\prime$ is at index $j$, increment $M[c_i][c_j]$  by 1. To ensure that we only need to use the upper triangle of the matrix, we will adopt the convention of always indexing such that $i < j$. \\

Create a priority queue $P$ with a min heap to keep track of the pair of sets with lowest conflict score, and add each cell not along the diagonal to $P$. Sets are identified with unique group ID numbers, and as new sets are created by merging, they are given incrementally larger group ID numbers. While the number of sets in $S$ is greater than the number of class times, classes still haven't been grouped into sufficiently few time slots, so merging must continue. \\

 At each step, find the sets $s_i$, $s_j$ with the minimum conflict score by popping from $P$. It is a common occurrence that one or both sets specified by $s_i$ and $s_j$ no longer "exist" - that is, the sets they represent have already been merged with some other set, in which case the pair is disregarded. Otherwise, an attempt is made to merge the sets. If $|s_i| + |s_j|$ is less than the number of classrooms, the sets can be merged without creating too large a time slot, so the sets are merged, otherwise that pair is also simply disregarded. When a merge takes place between $s_i$ and $s_j$ to form set $s_k$, the conflict score of any other set $s_o$ with $s_k$ should be the sum of $s_o$'s conflict scores with $s_i$ and $s_j$, since it now conflicts with all the classes in both, so row and column $j$ are added to row and column $i$, and $i$ is designated as the representative row/column of group $s_k$. Row/column $j$ continue to exist to avoid matrix resizing, but they are never again looked at. The $i^{th}$ row and column now represent the set $s_k$, which contains all the classes originally in either set $s_i$ or $s_j$. Join the two sets in $S$ as well.

Each iteration reduces the number of sets in $S$ by one. Once the number of sets in $S$ is equal the number of time slots, each class set can be arbitrarily assigned to a time slot.

Finally, we initialize a dictionary, S, whose keys are course numbers and values are dictionaries containing room, time, teacher, and student list for each course. We fill out this dictionary from the constraints such that:
\begin{enumerate}
    \item Each class group has a time, so every class in that group gets that time slot.
    \item The larger classes in a given class group get the larger rooms (this requires some sorting).
    \item The number of students in a class does not exceed the capacity of the assigned room (a simple check at the end of schedule creation).
\end{enumerate}

Teacher conflicts cannot arise in schedule creation because the handling of teacher conflicts is baked into the groups created from the conflict matrix. In this way, we create a valid schedule from our class groups.

\section{Pseudocode}
\begin{algorithm}
\SetKwFunction{Main}{Main}
\SetKwProg{Fn}{Function}{}{}
\Fn{\Main{Preferences, numClasses, Teachers}}{
let $n$ = len(numClasses);
initialize $M$ = n x n 2-D array of all 0's;

$M$ = setTeach($M$, $Teachers$);

$M$ = setCost($M$, $Preferences$);

createSets(M);


}
\end{algorithm}

\begin{algorithm}
\SetKwFunction{setTeach}{setTeach}
\SetKwProg{Fn}{Function}{}{}
\Fn{\setTeach{M, Teachers}}{
sort $Teachers$ by teacher id // Teachers is a list of class-teacher pairs \\
initialize $prev$ = Teachers[0] \\
\While{$i=1 < len(Teachers)$} {
let $teach$ = Teachers[i] \\
\If{teach[1] == prev[1]} {
set $M$[teach[0]][prev[0]] to $infinity$ // teacher teaches both classes \\
}
set $prev$ = Teachers[i] \\
i++ \\
}
\Return{$M$}
}
\end{algorithm}

\begin{algorithm}[H]
\SetKwFunction{setCost}{setCost}
\SetKwProg{Fn}{Function}{}{}
\Fn{\setCost{M, Preferences}}{
\For{student in Preferences} {
// Assume Preferences = [[p1,p2,p3,p4],[p1,p2,p3,p4],...]

\For{i in range(0:4)} {
{
\For{j in range(i+1:4)} {
let $c1$ = student[i]; let $c2$ = student[j];

$M$[$c1$][$c2$] += 1 // assuming unsorted/unweighted
}
}
}
}
}
\end{algorithm}

\begin{algorithm}[H]
\SetKwFunction{createSets}{createSets}
\SetKwProg{Fn}{Function}{}{}
\Fn{\createSets{M}}{
    \# M is an $n$ by $n$ matrix \\
    Initialize a union-find object, $S$ \\
    \For{each class}{
         Initialize a disjoint set of size one containing that class, stored in $S$ \\
    }
    Initialize a priority queue $P$ with all values from M in it \\
    \While{number of sets in $S$ $\geq$ the number of time slots}{
        Pop $(S_i, S_j)$ \\
        \If {either $S_i$ or $S_j$ has already been merged} {pass}
        \ElseIf{$|S_i|+|S_j| \leq$ the number of classrooms}{
            merge $S_k = S_i \cup S_j$ \\
            Add row and column $j$ to row and column $i$ \\
            Designate row and column $i$ as the location of $S_k$'s conflict scores \\
            Push all of $S_k$'s conflict scores to $P$ \\
        }
    }
    \For{each disjoint set $s$ in $S$}{
        assign $s$ to an unassigned time slot \\
        \For {each class $c$ in $s$}{
            assign $c$ to an unassigned classroom
        }
    }
\# write output to a file
}
\end{algorithm}

\begin{algorithm}
\SetKwFunction{createSchedule}{createSchedule}
\SetKwProg{Fn}{Function}{}{}
\Fn{\createSchedule{}}{
    initialize an empty dictionary, S \\
    roomSorted = sorted rooms by room size \\
    \For{each course}{
        S[course] = a dictionary containing 4 key-value pairs for room, teacher, time, and student list \\
    }
    \For{each course}{
        S[course][teacher] = teacher of that course, as given by constraints \\
    }
    \For{each preference list P}{
        \For{each course in P}{
            S[course][student list] = append the student whose preference list we are examining \\
        }
    }
    \# This next variable is used to compute groupSorted below \\
    classSorted = sorted courses by how many students want to take them \\
    \For{group,i in enumerate(classGroups)}{
        groupSorted = sort courses in group by how many students want to take them \\
        \For{each course,j in enumerate(groupSorted}{
            S[course][time] = i \\
            S[course][room] = $j^{th}$ element of roomSorted \\
        }
    }
    create a dictionary, R, from room constraint, where rooms are keys and room sizes are values \\
    \For{each course}{
        check that the size of it's students list is not greater than the room size of the room to which it's assigned \\
        If there are too many students, remove as many as needed until they fit into the given room size \\
    return S \\
    }
    }
\end{algorithm}

\# We have omitted the function that writes the output file, as it is merely an implementation detail once the schedule object has been created by \textit{createSchedule}. \\

\newpage
\section{Time Analysis}

Call the number of teachers $t$, the number of students $s$, and the number of classes $n$. \\

 setTeach contains a sort of teachers, which takes $O(t$log$t)$ time. Then it iterates over teachers performing constant time operations, so taking $O(t)$ time. Overall, setTeach is $O(t$log$t)$. \\

 setCost contains a triply nested loop, but the number of loops of the two inner loops is fixed rather than related to any input. Specifically, six innermost loops occur per student. Thus the total time is $O(s)$. \\

 createSets is a more complex function. The way it is written, initialization of the Union-Find, which contains one set per class, is $O(n)$. Initializing the priority queue is constant, but pushing all $O(n^2)$ values of $M$ to it is $O(n^2$log$(n^2)) = O(n^2$log$n)$. All sets must be merged by the time the priority queue is empty, so the maximum number of iterations of the \textbf{while} is no more than the maximum number of entries ever created in the priority queue $P$. Since every group merge reduces the number of class groups by 1, at most $n-1$ merges may take place, so at most $2n-1$ groups can ever be created before all classes are in one group. Each conflict score is between two groups, so the total number of possible conflicts to store in $P$ is $O((2n-1)^2) = O(n^2)$. The time of popping from $P$ is $O($log$(n^2)) = O($log$n)$. Checking whether a group has already been merged, checking the group sizes of $S_i$ and $S_j$, and merging sets are all constant time with our data structures. Adding rows and pushing them to $P$ can occur in total as many times as there are possible conflict scores, again $O(n^2)$, so it does not actually increase the time complexity of the \textbf{while}. Overall the most complex operations that occurs for every loop are the pop and push to $P$, which are $O($log$n)$, so the total complexity of the \textbf{while} is $O(n^2$log$n)$. Lastly, the double \textbf{for} iterates over all classes, performing a constant time operation of assignment, so its complexity is $O(n)$. The dominating complexity of createSets is $O(n^2$log$n)$. \\

 Each function is performed once during the algorithm's run, so the time complexity is their sum $O(t+s+n^2$log$n)$. Assuming that the number of classes taught by each teacher closely hews to an average, the number of teachers is linear relative to the number of classes - under this assumption, the algorithm thus far is $O(s + n^2$log$n)$.
 
 Finally, we have createSchedule. The initialization of S is O(1). Sorting the list of rooms is O(log(r)), where r is the number of rooms. The dictionary is implemented as a hash table, which will be unfortunate for this section of analysis, as – technically – worst case, insertion and search are O(k), where k is input size. Hence, it is worth noting that the dictionary was selected for its amazing O(1) \textit{average-case} complexity. Additionally, we note that the 'inner' dictionary contains only four key-value pairs, so insertion and search are constant. Continuing the analysis, the first for loop runs $n$ times and makes an insertion in each iteration, however, for \textbf{this} for loop, assignments are unlikely to generate hashing conflicts (as we are filling out the dictionary), so we do not consider them to be O(n), but rather, O(1). Thus, the first for loop is O(n). The second for loop runs $n$ times and makes an insertion at each iteration, so it is O($n^2$). The third and fourth for loops are nested, but the fourth for loop only runs the size of the student preference lists, which is constant. The third for loop runs $s$ times, and an insertion is made during each iteration. Thus, the third and fourth for loops run in O($sn$) time. The fifth and sixth for loops are nested, but the fifth iterates over a constant number of class times, so we only consider the sixth for loop for time complexity analysis. It runs $n$ times, making two insertions, so it runs in O($n^2$) time. The seventh for loop iterates over all courses, running $n$ times, doing a lookup at each iteration and removing at most $n-1$ students if there are too many students for a given room size. So the seventh for loop runs in O($n*(n+n-1)$) $\in$ O($n^2$) time. Since we don't know whether $s$ is bigger than $n$, we cannot be sure which term dominates, and thus, createSets runs in O($sn+n^2$) time. \\
 
 Hence, the algorithm runs in $O(sn + n^2$log$n)$. \\

\section{Discussion}

We had a relatively good intuition when approaching this problem that we had to somehow compute a cost associated with having classes at the same time. One option we considered was to weight the cost according to how many students preferred a given class. In other words, for every student that lists some class as their first choice, add a cost of 4 to that class. For every student who lists it as their second choice, add a cost of 3, etc. We realized that although this would determine a set of highly preferred classes that may have a number of students wanting to take them (and thus should not overlap), it loses the logic about what each student wants. A counter example to our initial approach is that there are two popular courses but they occur in different majors. There may be a lot of students who prefer those classes, but few students will desire to take both courses. Thus, it would be reasonable for those classes to overlap. This led us to our current algorithm which makes decisions based on the cost to each student of having two classes overlap. The aspects of this problem which made it difficult to determine an algorithm are:
\begin{enumerate}
\item{How do we quantify the cost of two classes overlapping?}
\begin{itemize}
\item{We decided to set it up such that merging courses is a direct function of the number of students who desire to take both}
\end{itemize}
\item{After a minimum cost is found and then a merge takes place, the cost of merging any third class with the new set will have to include the total merge cost of the third class with every class already in the set} 
\begin{itemize}
\item{This fact led us to the idea of merging matrix rows/columns to reflect the additive costs when sets are merged}
\end{itemize}
\item{A given teacher cannot teach more than one class at a given time}
\begin{itemize}
\item{This issue led us to perform the initialization step of setting matrix cells coorresponding to classes taught by the same teacher to Infinity}
\end{itemize}
\item{A given time slot cannot have more classes scheduled than the given number of rooms}
\begin{itemize}
\item{Because of this, we decided to check to see if this condition is broken and if so, skip that merge}
\end{itemize}
\end{enumerate}
This algorithm is {\bf greedy} because each time work is done, it generally follows a simple rule: merge sets with the lowest merge cost (if a merge is valid). This algorithm is not too different from constructing a minimum spanning tree using Kruskal's algorithm. Classes can be thought of as nodes in a graph and merge cost can be thought of as the weight of the edge between nodes. Similar to a minimum spanning tree, minimum edge weights are selected as the sets are constructed (merged). 

\subsection{Implementation}
We chose to implement this algorithm in Python. Much of the implementation followed directly from our design and pseudocode. We were able to utilize the {\it unionfind} package hosted on {\it https://pypi.org} (licensed to The Python Software Foundation). We needed to modify the implementation slightly to allow for sets to contain more information (class IDs). We also implemented our own min heap to serve as the priority queue. There was one key addition to the algorithm we noticed when attempting to implement. When a set is popped from the priority queue, it's possible that it has already been {\it unioned} with a previously popped set (which would have then been pushed back onto the queue). Thus, we keep track of what has been {\it unioned} and if we pop a set that has been {\it unioned} already, we throw it away and continue with the next set on the queue. This change has been added to our description and pseudocode.

We chose to implement the final schedule as a nested dictionary: each course number is a key that corresponds to a dictionary value; this 'inner' dictionary contains keys whose corresponding values are the teacher, time, room, and student list for the course. We chose this implementation because the schedule information will be accessed often (by students, teachers, and the registrar alike) once it is computed, and the hash table behind Python's built-in dictionary allows for average-case O(1) lookup. 

\section{Experimental Analysis}
\subsection{Performance}
The algorithm was tested using a number of different random test cases where the number of classes, students, times, and rooms were varried. These results are summarized in Table 1. In many cases the algorithm quickly produced a schedule (in less than 1 second), except for a few with large inputs. Furthermore, many of the resultant schedules were relatively optimal, with a mean of 94\% of students (and a $10^{th}$ percentile of 92\% of students) ultimately enrolled in their preferred classes.
\begin{table}[h]
\centering
\begin{tabular}{lllllllll}
no. & Classes & Students & Times & Rooms & Time (sec) & Best   & Experimental & \% Optimality \\
1   & 20      & 100      & 5     & 10    & 0.0094     & 400    & 324          & 0.81         \\
2   & 20      & 100      & 10    & 5     & 0.0060     & 400    & 381          & 0.9525       \\
3   & 20      & 200      & 5     & 10    & 0.0127     & 800    & 637          & 0.79625      \\
4   & 20      & 200      & 10    & 5     & 0.0111     & 800    & 758          & 0.9475       \\
5   & 40      & 200      & 10    & 20    & 0.0349     & 800    & 749          & 0.93625      \\
6   & 40      & 200      & 20    & 10    & 0.0220     & 800    & 772          & 0.965        \\
7   & 40      & 400      & 10    & 20    & 0.0390     & 1600   & 1469         & 0.918125     \\
8   & 40      & 400      & 20    & 10    & 0.0276     & 1600   & 1560         & 0.975        \\
9   & 80      & 400      & 30    & 30    & 0.0904     & 1600   & 1522         & 0.95125      \\
10  & 80      & 600      & 30    & 30    & 0.1016     & 2400   & 2312         & 0.963333333  \\
11  & 100     & 600      & 30    & 30    & 0.1567     & 2400   & 2286         & 0.9525       \\
12  & 100     & 800      & 30    & 30    & 0.1595     & 3200   & 3073         & 0.9603125    \\
13  & 100     & 1000     & 30    & 30    & 0.1638     & 4000   & 3863         & 0.96575      \\
14  & 100     & 2000     & 30    & 30    & 0.1869     & 8000   & 7843         & 0.980375     \\
15  & 200     & 1000     & 30    & 30    & 0.6815     & 4000   & 3752         & 0.938        \\
16  & 200     & 2000     & 30    & 30    & 0.7009     & 8000   & 7679         & 0.959875     \\
17  & 200     & 3000     & 30    & 30    & 0.7316     & 12000  & 11701        & 0.975083333  \\
18  & 500     & 1000     & 60    & 50    & 5.1768     & 4000   & 3714         & 0.9285       \\
19  & 500     & 2000     & 60    & 50    & 5.1586     & 8000   & 7536         & 0.942        \\
20  & 500     & 5000     & 60    & 50    & 5.1397     & 20000  & 19257        & 0.96285      \\
21  & 500     & 10000    & 60    & 50    & 5.2976     & 40000  & 39061        & 0.976525     \\
22  & 2000    & 40000    & 60    & 300   & 117.0473   & 160000 & 156211       & 0.97631875  
\end{tabular}
\caption{Results of running the algorithm with various parameters}
\label{my-label}
\end{table}
Because we suspect that the time of the algorithm is largely dominated by the number of classes ($n$), we decided to plot class size against running time for the various experiments above. According to our timing analysis the algorithm should run $O(n^2logn)$. For this reason, we plotted the number of classes against the square root of the time to try and observe a linear relationship. Because of the nature of the way we increased class number, we decided to report it on a log scale. The results of this can be seen in Figure 1. We observe a relatively linear relationship suggesting that the running time is squared in the number of classes.
\begin{figure}[h]
\includegraphics[width=\linewidth]{"Timing Data".png}
\centering
\caption{The square of running time as a function of the number of classes (log scale) for the experimental results.}
\end{figure}
\subsection{Design Error}
After testing the algorithm, we realized that there is a flaw in the design that is capable of producing invalid schedules. If a circumstance is arranged such that the number of rooms is somewhat constrained (relative to the number of classes), the algorithm may find itself backed into a corner due to the \textbf {greedy} approach. At any time, a set combination may be popped from the priority queue which currently has the minimum conflict. However, merging these sets would produce a set which is too large (greater than the number of available rooms) and this combination is ignored. If this occurs continuously, eventually a merge will take place with an infinite conflict score, corresponding to two courses taught by the same teacher. Since there is no way to backtrack and "unmerge" sets, there is no choice but to merge them, which produces an invalid schedule. Again, this is only observed when the number of available rooms is small. For the haverford data, as well as a number of "realistic" random tests, we did not encounter this problem. However, it is important to note that it is present and a direct drawback from the \textbf {greedy} approach.

If we want to ensure that a valid schedule is always formed, we could relax the restriction on the maximum size of a set. Then, all merges will be minimum. For any set which is ultimately larger than the number of available rooms we can randomly remove classes and merge them into one of the other smaller sets. If all other sets produce infinite conflicts, then pick a new class to attempt to move. If there is such a time when all classes in the overfilled time slot conflict infinitely with all other sets, then pick the course with the minimum student interest and remove it altogether (do not schedule it at all).

This may create problems with our optimality for cases where this issue would never arise. At some step in the algorithm, merging the "next best option" may be better than the result of the above process. To handle this, our algorithm could proceed normally and if and only if infinitely conflicting courses are merged, the algorithm starts over following the above design. Ultimately these desicions balance the choice between optimality and complexity and may be case-dependent. 

\section{Additional Constraints}

\begin{enumerate}
\item{\textbf{Weighted Preference Costs}}

When students select which classes they are going to take, it is rarely the case that taking each course bears equal importance to their academic persuits. An example of this could be courses a student needs for their major or minor. Another example may be courses a student needs to take in order to fulfill remaining distribution requirements. The current student preferences file convention does not weight a given student's desired courses, it assumes that any combination of courses occurring at the same time is equally problematic. However, if we enforce that students sort their courses in order of preference and weight each one up to a total constant weight value (we chose 10), then we can compute the cost of merging according to the following forumla:\\

$cost(c_i,c_j) = weight[c_i] + weight[c_j]$

This way, courses with higher weights have a higher overlap cost than courses with lower weights. Our algorithm takes this convention into account when it sets costs. When our program is run with the flag "--weights", it looks for a file constructed according to the convention below. Then, conflicts are computed according to the above formula. Total maximum student preference value is also re-computed along this process because it will be a function of not just whether a student is enrolled in a course, but also of the $weight$ of the courses they are enrolled in. Since we have constrained the weight to 10, this is just $10\times \#students$. Once a schedule is generated, the student preference value is checked using our added script "pref\_value\_sorted.py". Note that "is\_valid.pl" must still be used to report schedule accuracy, but the value it gives for student preference does not take priorities into account.\\

The added constraints are passed through a file of the following format:\\

student\qquad weights \\
1\qquad 5 3 1 1 \\
2\qquad 4 2 2 1 1 \\
3\qquad 3 3 2 2  \\

Where weights are space-separated weights (totalling 10) for each student ordered the same as the student's list of classes in the preferences file

Registering for two courses does not mean that one wants to enroll in them equally. Thus, it is important to consider which courses would be most problematic to overlap. For this reason, adopting this added constraint improves the overall optimality of the algorithm in computing high preference schedules. The take away from this design change is that when scheduling courses, the registrar should take into account the (implicit) preferences of students. For example, if there are a lot of students who are computer science majors / math minors, a number of students will highly prefer taking those courses concurrently and they shouldn't be scheduled together. Similarly, if a number of junior computer science majors have outstandind distribution requirements in the humanities, the registrar should ensure that not too many CS courses are scheduled on top of humanities courses.\\

\item{\textbf{Conflict Assumptions}}\\
In reality, the registrar does not have student preferences to work with. Therefore, it is impossible to use our algorithm to make scheduling decisions. We can, however, use our algorithm to check the accuracy of an implementable standard for course scheduling. In this case, we wanted to test the assumption that 100-level and 300-level courses in the same department/subject are rarely taken by the one student. To do this, we wrote a script "dept\_level\_data.py" which parses Haverford Enrollment Data to output the subject and level for each course and writes it to a file "DeptLevels.txt". This file can be supplied to our algorithm following the flag "--levels". With this added information, the algorithm sets 100-level and 300-level courses from the same subject to $0$ conflict in the conflict matrix $M$, regardless of what they were set to before (unless it was "Infinity" - one teacher still cannot teach two courses at the same time). This effectively enforces the assumption that such a course pair will not have any individual student interest. The algorithm is then able to run normally. The results of this change are summarized in Table 2.\\

\begin{table}[h]
\centering
\begin{tabular}{lllll}
Experiment        & Time          & Best & Experimental & \% Optimality \\
Regular Algorithm & 2.94600010    & 4427 & 3718         & 0.83985       \\
With Assumption   & 3.00800013542 & 4427 & 3697         & 0.83510      
\end{tabular}
\caption{Results of running the algorithm on Haverford Data with and without the added constraint}
\label{my-label}
\end{table}

It makes sense that the added constraint adds a bit of time because it iterates over M a second time and modifies the values. This extra complexity could be avoided by checking the courses when costs are initially set, however the focus of this experiment was to evaluate optimality. It is clear that the total preference value only dropped marginally by enforcing this assumption. After seeing this, we wanted to probe the enrollment data further to see which courses contribute to this marginal drop in optimality.

After analyzing the Haverford Data further, we found that in 2014, there were 44 cases of a student concurrently enrolling in a 100-level and 300-level course in the same subject. We also found that these 44 cases were confined to only 13 departments. In many cases, there were a few (1-3) instances for a given department, but some (Political Science, Music, and Psychology) had a higher number of occurences (5-9), as shown in Table 3.\\

\begin{table}[h]
\centering
\begin{tabular}{llll}
Subject & Occurrences & Subject & Occurrences \\
CITY    & 1           & RELG    & 3           \\
SOCL    & 1           & ARTS    & 3           \\
SPAN    & 1           & ANTH    & 3           \\
ICPR    & 1           & MUSC    & 5           \\
HIST    & 1           & POLS    & 9           \\
PHIL    & 1           & PSYC    & 11          \\
LING    & 2           &         &             \\        
\end{tabular}
\caption{Occurrences per subject of concurrent enrollment in a 100- and 300-level course in one subject}
\label{my-label}
\end{table}

The results of this experiment show that the registrar can produce relatively optimal schedules by scheduling 100- and 300-level courses from the same subject at the same time (as long as they are not taught by the same teacher). In fact, if the above trends are observed over various years, the registrar may avoid grouping together 100- and 300-level courses from subjects like Political Science and Psychology, but group together 100- and 300-level courses from other subjects and improve the optimality of course scheduling.\\


\item{}

\item{}

\item{}

\end{enumerate}


\end{document}